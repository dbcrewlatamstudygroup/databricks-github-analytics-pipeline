# **Fase 1: ConfiguraciÃ³n del Entorno en Databricks**

## **IntroducciÃ³n**

Antes de poder construir cualquier pipeline de datos, necesitamos preparar nuestro espacio de trabajo. Esto implica registrarnos en Databricks Community Edition, crear un clÃºster computacional, y configurar Azure Storage Account como nuestro sistema de almacenamiento externo. Esta configuraciÃ³n nos permitirÃ¡ implementar la **Medallion Architecture** (Bronze-Silver-Gold) para nuestro proyecto de anÃ¡lisis de datos de GitHub.

-----

## **Paso 1.1: Registrarse en Databricks Community Edition**

La Community Edition es una versiÃ³n gratuita de Databricks, ideal para aprender y desarrollar proyectos personales.

### **Proceso de Registro:**

1. **Ve a la pÃ¡gina de registro:**
- Abre tu navegador y dirÃ­gete a: [Databricks Community Edition](https://community.cloud.databricks.com/login.html)
1. **Completa el formulario:**
- Rellena tus datos personales
- AsegÃºrate de usar un correo electrÃ³nico vÃ¡lido
- Crea una contraseÃ±a segura
1. **Selecciona la opciÃ³n â€œCommunity Editionâ€:**
- Cuando se te presente la opciÃ³n de elegir un plan
- Selecciona **â€œGet started with Community Editionâ€**
1. **Verifica tu correo electrÃ³nico:**
- RecibirÃ¡s un correo para confirmar tu cuenta
- Sigue las instrucciones para activar tu workspace

### **Material de Apoyo:**

- **DocumentaciÃ³n Oficial:** [GuÃ­a de inicio de Databricks](https://docs.databricks.com/getting-started/community-edition.html)

-----

## **Paso 1.2: Explorando la Interfaz de Databricks**

Una vez dentro de tu workspace, familiarÃ­zate con la interfaz principal.

### **Componentes Principales:**

|SecciÃ³n      |DescripciÃ³n                            |Uso en el Proyecto                |
|-------------|---------------------------------------|----------------------------------|
|**Workspace**|Organiza carpetas, notebooks y archivos|Crear estructura del proyecto     |
|**Compute**  |Gestiona clÃºsteres computacionales     |Crear y administrar el clÃºster    |
|**Data**     |Explora bases de datos y tablas        |Visualizar datos transformados    |
|**Jobs**     |Automatiza ejecuciÃ³n de notebooks      |Para etapas avanzadas del proyecto|

### **NavegaciÃ³n BÃ¡sica:**

- **MenÃº lateral izquierdo:** Acceso rÃ¡pido a todas las secciones
- **Ãrea principal:** Espacio de trabajo principal
- **Barra superior:** Configuraciones de usuario y workspace

-----

## **Paso 1.3: Verificando tu Entorno Computacional**

Databricks Community Edition viene con un **Serverless Starter Warehouse** preconfigurado que actuarÃ¡ como nuestro motor computacional para procesar datos.

### **VerificaciÃ³n del Serverless Warehouse:**

1. **Navega a la secciÃ³n "Compute":**
   - Haz clic en el Ã­cono **"Compute"** en el menÃº lateral

2. **Verificar el Serverless Warehouse:**
   - DeberÃ­as ver un warehouse llamado **"Starter Warehouse"** o similar
   - **Estado:** Debe aparecer como "Running" o con un cÃ­rculo verde
   - **Tipo:** Serverless (Sin necesidad de configuraciÃ³n manual)

3. **Si el warehouse no estÃ¡ activo:**
   - Haz clic en el warehouse para seleccionarlo
   - Clic en **"Start"** si estÃ¡ detenido
   - El proceso toma 1-2 minutos en iniciarse

4. **VerificaciÃ³n completa:**
   - **Estado activo:** CÃ­rculo verde junto al nombre
   - **Tipo:** Serverless Starter Warehouse
   - **Listo para usar:** Sin configuraciÃ³n adicional necesaria

### **Limitaciones Community Edition:**
- âœ… **Permitido:** Serverless Starter Warehouse (Ya creado)
- âŒ **Limitado:** Sin acceso a funcionalidades premium
- âŒ **Limitado:** Sin almacenamiento persistente integrado

### **Material de Apoyo:**
- **DocumentaciÃ³n Oficial:** [Databricks Serverless Compute](https://docs.databricks.com/compute/serverless.html)

-----

## **Paso 1.4: Configurando Azure Storage Account**

Dado que Databricks Community Edition no permite almacenamiento persistente integrado, configuraremos Azure Storage Account como nuestro sistema de almacenamiento externo.

### **0. ValidaciÃ³n del Acceso a Azure**

#### **InformaciÃ³n del Proyecto:**
- **Grupo de Recursos:** `rg-proyecto-github`
- **Storage Account:** `stgaccproyectogh`

#### **VerificaciÃ³n de Permisos (Paso a Paso):**

1. **Acceder al grupo de recursos:**
   - Ve a: [Azure Portal](https://portal.azure.com)
   - En la barra de bÃºsqueda superior, escribe: `rg-proyecto-github`
   - Haz clic en el grupo de recursos **"rg-proyecto-github"** cuando aparezca en los resultados
   - Esto te llevarÃ¡ al dashboard del grupo de recursos

2. **Navegar a Access Control (IAM):**
   - MenÃº lateral â†’ **"Access control (IAM)"**
   - PestaÃ±as superiores visibles

3. **Verificar permisos especÃ­ficos:**
   - SecciÃ³n **"My access"** â†’ BotÃ³n **"View my access"**
   - Panel derecho: **"assignments - rg-proyecto-github"**

4. **Confirmar roles asignados:**

| Role | Description | Scope | Status |
|------|-------------|-------|--------|
| **Reader** | View all resources, but does not allow modifications | Subscription (inherited) | âœ… Requerido |
| **Storage Account Contributor** | Lets you manage storage accounts and access keys | This resource | âœ… Requerido |
| **Storage Blob Data Contributor** | Allows for read, write and delete access to blobs | This resource | âœ… Requerido |

#### **ObtenciÃ³n de Credenciales:**

1. **Localizar Storage Account:**
   - En el grupo de recursos, buscar el recurso **"stgaccproyectogh"** (tipo: Storage account)
   - Hacer clic en el nombre del Storage Account: **stgaccproyectogh**

2. **Acceder a las claves:**
   - MenÃº lateral â†’ **"Security + networking"** â†’ **"Access keys"**
   - Copiar **Storage account name:** `stgaccproyectogh`
   - Revelar y copiar **Key 1** o **Key 2**

### **1. Configurar Databricks Secrets**

#### **ğŸ’¡ Enfoque HÃ­brido: UI + Python SDK**

**Ventajas de este mÃ©todo:**
- âœ… **UI para Scope:** Visual y fÃ¡cil de entender
- âœ… **SDK para Secrets:** ProgramÃ¡tico y reproducible  
- âœ… **Sin limitaciones:** No depende de URLs especÃ­ficas
- âœ… **MÃ¡s control:** Manejo directo de errores
- âœ… **Documentable:** CÃ³digo que se puede versionar

Utilizaremos la **interfaz web** para crear el scope (mÃ¡s visual) y **Python SDK** para agregar secrets (mÃ¡s programÃ¡tico y reproducible).

#### **Crear Secret Scope (Desde la UI):**

1. **Navegar a secrets en Databricks:**
   - En tu workspace de Databricks, agrega `#secrets/createScope` al final de la URL
   - URL: `https://tu-workspace.cloud.databricks.com/#secrets/createScope`

2. **Configurar el Scope:**
   - **Scope Name:** `azure-storage-secrets`
   - **Manage Principal:** Creator (por defecto)
   - Haz clic en **"Create"**

#### **Agregar Secrets (Usando Python SDK):**

Una vez creado el scope, ejecuta este cÃ³digo en una celda de tu notebook:

```python
# Instalar Databricks SDK si no estÃ¡ disponible
%pip install databricks-sdk

# Importar y configurar el cliente
from databricks.sdk import WorkspaceClient

# Inicializar cliente de Databricks
w = WorkspaceClient()

# Agregar el nombre del Storage Account
w.secrets.put_secret(
    scope="azure-storage-secrets",
    key="storage-account-name", 
    string_value="stgaccproyectogh"
)

# Agregar la clave de acceso del Storage Account
# IMPORTANTE: Reemplaza "TU_STORAGE_ACCOUNT_KEY" con la clave real obtenida del Portal Azure
w.secrets.put_secret(
    scope="azure-storage-secrets",
    key="storage-account-key",
    string_value="TU_STORAGE_ACCOUNT_KEY"  # â† Reemplazar con la clave real
)

print("âœ… Secrets configurados exitosamente:")
print("   - storage-account-name: stgaccproyectogh")
print("   - storage-account-key: [OCULTA]")
```

#### **Verificar Secrets Configurados:**

```python
# Verificar que los secrets se crearon correctamente
try:
    # Listar scopes
    scopes = w.secrets.list_scopes()
    target_scope = "azure-storage-secrets"
    
    if any(scope.name == target_scope for scope in scopes):
        print(f"âœ… Scope '{target_scope}' encontrado")
        
        # Listar secrets en el scope
        secrets = w.secrets.list_secrets(scope=target_scope)
        secret_keys = [secret.key for secret in secrets]
        print(f"ğŸ”‘ Secrets disponibles: {secret_keys}")
        
        # Verificar que tenemos los secrets necesarios
        required_keys = ["storage-account-name", "storage-account-key"]
        if all(key in secret_keys for key in required_keys):
            print("ğŸ‰ Todos los secrets requeridos estÃ¡n configurados")
        else:
            missing = [key for key in required_keys if key not in secret_keys]
            print(f"âŒ Faltan estos secrets: {missing}")
    else:
        print(f"âŒ Scope '{target_scope}' no encontrado")
        
except Exception as e:
    print(f"âŒ Error verificando secrets: {e}")
```

### **2. Configurar ConexiÃ³n en Databricks**

#### **CÃ³digo de ConfiguraciÃ³n (Notebook):**

```python
# Verificar configuraciÃ³n de secrets usando dbutils (mÃ©todo tradicional)
print("ğŸ” Verificando configuraciÃ³n de secrets...")
try:
    scopes = dbutils.secrets.listScopes()
    target_scope = "azure-storage-secrets"
    
    if target_scope in [scope.name for scope in scopes]:
        secrets = dbutils.secrets.list(target_scope)
        secret_keys = [secret.key for secret in secrets]
        print(f"âœ… Scope encontrado: {target_scope}")
        print(f"ğŸ”‘ Secrets disponibles: {secret_keys}")
        
        # Verificar que tenemos los secrets necesarios
        required_keys = ["storage-account-name", "storage-account-key"]
        if all(key in secret_keys for key in required_keys):
            print("ğŸ‰ Todos los secrets requeridos estÃ¡n configurados")
        else:
            missing = [key for key in required_keys if key not in secret_keys]
            print(f"âŒ Faltan estos secrets: {missing}")
    else:
        print(f"âŒ Scope '{target_scope}' no encontrado")
        
except Exception as e:
    print(f"âŒ Error: {e}")
```

```python
# Configurar cliente de Azure Storage
%pip install azure-storage-blob

from azure.storage.blob import BlobServiceClient

def get_storage_client():
    try:
        # Obtener credenciales desde secrets
        storage_account_name = dbutils.secrets.get(scope="azure-storage-secrets", key="storage-account-name")
        storage_account_key = dbutils.secrets.get(scope="azure-storage-secrets", key="storage-account-key")
        
        # Crear connection string
        connection_string = f"DefaultEndpointsProtocol=https;AccountName={storage_account_name};AccountKey={storage_account_key};EndpointSuffix=core.windows.net"
        
        # Crear cliente
        blob_service_client = BlobServiceClient.from_connection_string(connection_string)
        
        # Test de conexiÃ³n
        containers = list(blob_service_client.list_containers())
        print(f"âœ… Conectado a Azure Storage: {storage_account_name}")
        print(f"ğŸ“¦ Contenedores encontrados: {len(containers)}")
        
        return blob_service_client
        
    except Exception as e:
        print(f"âŒ Error de conexiÃ³n: {e}")
        return None

# Inicializar cliente
storage_client = get_storage_client()
```

### **3. Crear Estructura del Proyecto**

En este paso vas a crear un contenedor con la siguiente sintaxis:
> primeraLetraNombrePrimerApellido-proyecto-gh -->> Ejemplo alopez-proyecto-gh


Validar que no exista otro contenedor ya creado con este nombre, si es asi utiliza la siguiente sintaxis:
> primeraLetraNombrePrimerApellidoPrimeraLetraSegundoApellido-proyecto-gh -->> Ejemplo alopezm-proyecto-gh

#### **Configurar Medallion Architecture:**

```python
# ConfiguraciÃ³n del proyecto
container_name = "nombre-contenedor"
folders = ["bronze", "silver", "gold"]

def setup_project_structure():
    if not storage_client:
        print("âŒ Cliente no disponible")
        return False
    
    try:
        # Crear contenedor
        try:
            container_client = storage_client.create_container(container_name)
            print(f"âœ… Contenedor '{container_name}' creado")
        except Exception as e:
            if "ContainerAlreadyExists" in str(e):
                print(f"â„¹ï¸  Contenedor '{container_name}' ya existe")
        
        # Crear carpetas (Bronze, Silver, Gold)
        for folder in folders:
            blob_name = f"{folder}/.placeholder"
            blob_client = storage_client.get_blob_client(container=container_name, blob=blob_name)
            blob_client.upload_blob(f"# Carpeta {folder} - Medallion Architecture", overwrite=True)
            print(f"âœ… Carpeta '{folder}' creada")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        return False

# Ejecutar configuraciÃ³n
setup_project_structure()
```

### **4. Verificar ConfiguraciÃ³n Completa**

#### **Checklist de ValidaciÃ³n:**

```python
# VerificaciÃ³n final de la configuraciÃ³n
def verify_complete_setup():
    print("ğŸ” VERIFICACIÃ“N COMPLETA DEL ENTORNO")
    print("=" * 50)
    
    checks = []
    
    # Check 1: Databricks Secrets
    try:
        dbutils.secrets.get("azure-storage-secrets", "storage-account-name")
        checks.append("âœ… Databricks Secrets configurados")
    except:
        checks.append("âŒ Databricks Secrets faltantes")
    
    # Check 2: Azure Storage Connection
    if storage_client:
        checks.append("âœ… ConexiÃ³n a Azure Storage")
    else:
        checks.append("âŒ Sin conexiÃ³n a Azure Storage")
    
    # Check 3: Estructura del proyecto
    try:
        container_client = storage_client.get_container_client(container_name)
        blobs = list(container_client.list_blobs())
        if len(blobs) >= 3:
            checks.append("âœ… Estructura Medallion creada")
        else:
            checks.append("âŒ Estructura Medallion incompleta")
    except:
        checks.append("âŒ Error verificando estructura")
    
    # Mostrar resultados
    for check in checks:
        print(f"   {check}")
    
    all_good = all("âœ…" in check for check in checks)
    
    if all_good:
        print("\nğŸ‰ Â¡ConfiguraciÃ³n completa y exitosa!")
        print("ğŸ“ Listo para la Fase 2: Carga de datos")
    else:
        print("\nâš ï¸  Hay elementos por configurar")
        print("ğŸ“ Revisa los elementos marcados con âŒ")

# Ejecutar verificaciÃ³n
verify_complete_setup()
```

-----

## **Resumen de la Fase 1**

### **âœ… Elementos Configurados:**

1. **Databricks Community Edition**
   - âœ… Cuenta creada y verificada
   - âœ… Workspace activo
   - âœ… Interfaz explorada

2. **Serverless Warehouse**
   - âœ… Starter Warehouse verificado y activo
   - âœ… Estado "Running" confirmado
   - âœ… Listo para procesar datos

3. **Azure Storage Account**
   - âœ… Permisos verificados en Portal Azure
   - âœ… Storage Account `stgaccproyectogh` configurado  
   - âœ… Databricks Secrets configurados (UI + SDK)
   - âœ… ConexiÃ³n establecida y probada

4. **Estructura del Proyecto**
   - âœ… Contenedor `nombre-contenedor` creado
   - âœ… Medallion Architecture implementada:
     - ğŸ¥‰ **Bronze:** Datos en bruto
     - ğŸ¥ˆ **Silver:** Datos procesados
     - ğŸ¥‡ **Gold:** Datos para anÃ¡lisis

### **ğŸ¯ PrÃ³ximo Paso:**

**[â¡ï¸ Fase 2: Carga y Almacenamiento (Capa Bronze)](./fase-2-capa-bronze.md)**

### **ğŸ“š Material de Apoyo:**

- **Databricks:** [DocumentaciÃ³n Oficial](https://docs.databricks.com/getting-started/index.html)
- **Databricks SDK:** [Python SDK Documentation](https://databricks-sdk-py.readthedocs.io/)
- **Azure Storage:** [GuÃ­a de Python SDK](https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-python)
- **Medallion Architecture:** [Conceptos y mejores prÃ¡cticas](https://databricks.com/glossary/medallion-architecture)