# **Fase 1: Configuraci√≥n del Entorno en Databricks**

## **Introducci√≥n**

Antes de poder construir cualquier pipeline de datos, necesitamos preparar nuestro espacio de trabajo. Esto implica registrarnos en Databricks Community Edition, crear un cl√∫ster computacional, y configurar Azure Storage Account como nuestro sistema de almacenamiento externo. Esta configuraci√≥n nos permitir√° implementar la **Medallion Architecture** (Bronze-Silver-Gold) para nuestro proyecto de an√°lisis de datos de GitHub.

-----

## **Paso 1.1: Registrarse en Databricks Community Edition**

La Community Edition es una versi√≥n gratuita de Databricks, ideal para aprender y desarrollar proyectos personales.

### **Proceso de Registro:**

1. **Ve a la p√°gina de registro:**
- Abre tu navegador y dir√≠gete a: [Databricks Community Edition](https://community.cloud.databricks.com/login.html)
1. **Completa el formulario:**
- Rellena tus datos personales
- Aseg√∫rate de usar un correo electr√≥nico v√°lido
- Crea una contrase√±a segura
1. **Selecciona la opci√≥n ‚ÄúCommunity Edition‚Äù:**
- Cuando se te presente la opci√≥n de elegir un plan
- Selecciona **‚ÄúGet started with Community Edition‚Äù**
1. **Verifica tu correo electr√≥nico:**
- Recibir√°s un correo para confirmar tu cuenta
- Sigue las instrucciones para activar tu workspace

### **Material de Apoyo:**

- **Documentaci√≥n Oficial:** [Gu√≠a de inicio de Databricks](https://docs.databricks.com/getting-started/community-edition.html)

-----

## **Paso 1.2: Explorando la Interfaz de Databricks**

Una vez dentro de tu workspace, familiar√≠zate con la interfaz principal.

### **Componentes Principales:**

|Secci√≥n      |Descripci√≥n                            |Uso en el Proyecto                |
|-------------|---------------------------------------|----------------------------------|
|**Workspace**|Organiza carpetas, notebooks y archivos|Crear estructura del proyecto     |
|**Compute**  |Gestiona cl√∫steres computacionales     |Crear y administrar el cl√∫ster    |
|**Data**     |Explora bases de datos y tablas        |Visualizar datos transformados    |
|**Jobs**     |Automatiza ejecuci√≥n de notebooks      |Para etapas avanzadas del proyecto|

### **Navegaci√≥n B√°sica:**

- **Men√∫ lateral izquierdo:** Acceso r√°pido a todas las secciones
- **√Årea principal:** Espacio de trabajo principal
- **Barra superior:** Configuraciones de usuario y workspace

-----

## **Paso 1.3: Creando tu Primer Cl√∫ster**

El cl√∫ster es el motor computacional que procesar√° tus datos. Sin √©l, los notebooks no pueden ejecutar c√≥digo.

### **Configuraci√≥n del Cl√∫ster:**

1. **Navega a la secci√≥n ‚ÄúCompute‚Äù:**
- Haz clic en el √≠cono **‚ÄúCompute‚Äù** en el men√∫ lateral
1. **Crear un nuevo cl√∫ster:**
- Haz clic en **‚ÄúCreate Compute‚Äù**
1. **Configuraci√≥n recomendada:**
- **Cluster Name:** `cluster-proyecto-github`
- **Databricks Runtime Version:** Selecciona la versi√≥n **LTS** m√°s reciente (no Beta)
- **Worker Type:** Mantener configuraci√≥n por defecto
- **Driver Type:** Mantener configuraci√≥n por defecto
- **Autoscaling:** Mantener habilitado
1. **Iniciar el cl√∫ster:**
- Haz clic en **‚ÄúCreate Cluster‚Äù**
- El proceso toma entre 3-5 minutos
- **Estado listo:** C√≠rculo verde junto al nombre

### **Limitaciones Community Edition:**

- ‚úÖ **Permitido:** 1 cl√∫ster activo
- ‚úÖ **Permitido:** Hasta 2 nodos worker
- ‚ùå **Limitado:** Sin acceso a funcionalidades premium
- ‚ùå **Limitado:** Sin almacenamiento persistente integrado

### **Material de Apoyo:**

- **Documentaci√≥n Oficial:** [Gu√≠a sobre Clusters en Databricks](https://docs.databricks.com/clusters/index.html)

-----

## **Paso 1.4: Configurando Azure Storage Account**

Dado que Databricks Community Edition no permite almacenamiento persistente integrado, configuraremos Azure Storage Account como nuestro sistema de almacenamiento externo.

### **0. Validaci√≥n del Acceso a Azure**

#### **Verificaci√≥n de Permisos (Paso a Paso):**

1. **Acceder al grupo de recursos:**
   
   ```
   URL: https://portal.azure.com/#@tu-tenant.onmicrosoft.com/resource/subscriptions/tu-subscription-id/resourceGroups/rg-proyecto-github/overview
   ```
1. **Navegar a Access Control (IAM):**
- Men√∫ lateral ‚Üí **‚ÄúAccess control (IAM)‚Äù**
- Pesta√±as superiores visibles
1. **Verificar permisos espec√≠ficos:**
- Secci√≥n **‚ÄúMy access‚Äù** ‚Üí Bot√≥n **‚ÄúView my access‚Äù**
- Panel derecho: **‚Äúassignments - rg-proyecto-github‚Äù**
1. **Confirmar roles asignados:**

|Role                             |Description                                         |Scope                   |Status     |
|---------------------------------|----------------------------------------------------|------------------------|-----------|
|**Reader**                       |View all resources, but does not allow modifications|Subscription (inherited)|‚úÖ Requerido|
|**Storage Account Contributor**  |Lets you manage storage accounts and access keys    |This resource           |‚úÖ Requerido|
|**Storage Blob Data Contributor**|Allows for read, write and delete access to blobs   |This resource           |‚úÖ Requerido|

#### **Obtenci√≥n de Credenciales:**

1. **Localizar Storage Account:**
- En el grupo de recursos, buscar recurso tipo **‚ÄúStorage account‚Äù**
- Hacer clic en el nombre del Storage Account
1. **Acceder a las claves:**
- Men√∫ lateral ‚Üí **‚ÄúSecurity + networking‚Äù** ‚Üí **‚ÄúAccess keys‚Äù**
- Copiar **Storage account name**
- Revelar y copiar **Key 1** o **Key 2**

### **1. Configurar Databricks Secrets**

#### **Crear Secret Scope:**

1. **Navegar a secrets:**
   
   ```
   URL: https://tu-workspace.cloud.databricks.com/#secrets/createScope
   ```
1. **Configuraci√≥n:**
- **Scope Name:** `azure-storage-secrets`
- **Manage Principal:** Creator
- **Backend Type:** Databricks

#### **Agregar Secrets:**

1. **Secret 1 - Nombre del Storage:**
   
   ```
   URL: https://tu-workspace.cloud.databricks.com/#secrets/createSecret
   ```
- **Scope:** `azure-storage-secrets`
- **Key:** `storage-account-name`
- **Value:** [Nombre del Storage Account]
1. **Secret 2 - Clave de Acceso:**
   
   ```
   URL: https://tu-workspace.cloud.databricks.com/#secrets/createSecret
   ```
- **Scope:** `azure-storage-secrets`
- **Key:** `storage-account-key`
- **Value:** [Clave completa del Storage Account]

### **2. Configurar Conexi√≥n en Databricks**

#### **C√≥digo de Configuraci√≥n (Notebook):**

```python
# Verificar configuraci√≥n de secrets
print("üîç Verificando configuraci√≥n de secrets...")
try:
    scopes = dbutils.secrets.listScopes()
    target_scope = "azure-storage-secrets"
    
    if target_scope in [scope.name for scope in scopes]:
        secrets = dbutils.secrets.list(target_scope)
        secret_keys = [secret.key for secret in secrets]
        print(f"‚úÖ Scope encontrado: {target_scope}")
        print(f"üîë Secrets disponibles: {secret_keys}")
    else:
        print(f"‚ùå Scope '{target_scope}' no encontrado")
        
except Exception as e:
    print(f"‚ùå Error: {e}")
```

```python
# Configurar cliente de Azure Storage
%pip install azure-storage-blob

from azure.storage.blob import BlobServiceClient

def get_storage_client():
    try:
        # Obtener credenciales desde secrets
        storage_account_name = dbutils.secrets.get(scope="azure-storage-secrets", key="storage-account-name")
        storage_account_key = dbutils.secrets.get(scope="azure-storage-secrets", key="storage-account-key")
        
        # Crear connection string
        connection_string = f"DefaultEndpointsProtocol=https;AccountName={storage_account_name};AccountKey={storage_account_key};EndpointSuffix=core.windows.net"
        
        # Crear cliente
        blob_service_client = BlobServiceClient.from_connection_string(connection_string)
        
        # Test de conexi√≥n
        containers = list(blob_service_client.list_containers())
        print(f"‚úÖ Conexi√≥n exitosa! Contenedores: {len(containers)}")
        
        return blob_service_client
        
    except Exception as e:
        print(f"‚ùå Error de conexi√≥n: {e}")
        return None

# Inicializar cliente
storage_client = get_storage_client()
```

### **3. Crear Estructura del Proyecto**

#### **Configurar Medallion Architecture:**

```python
# Configuraci√≥n del proyecto
container_name = "alopez-proyecto-gh"
folders = ["bronze", "silver", "gold"]

def setup_project_structure():
    if not storage_client:
        print("‚ùå Cliente no disponible")
        return False
    
    try:
        # Crear contenedor
        try:
            container_client = storage_client.create_container(container_name)
            print(f"‚úÖ Contenedor '{container_name}' creado")
        except Exception as e:
            if "ContainerAlreadyExists" in str(e):
                print(f"‚ÑπÔ∏è  Contenedor '{container_name}' ya existe")
        
        # Crear carpetas (Bronze, Silver, Gold)
        for folder in folders:
            blob_name = f"{folder}/.placeholder"
            blob_client = storage_client.get_blob_client(container=container_name, blob=blob_name)
            blob_client.upload_blob(f"# Carpeta {folder} - Medallion Architecture", overwrite=True)
            print(f"‚úÖ Carpeta '{folder}' creada")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error: {e}")
        return False

# Ejecutar configuraci√≥n
setup_project_structure()
```

### **4. Verificar Configuraci√≥n Completa**

#### **Checklist de Validaci√≥n:**

```python
# Verificaci√≥n final de la configuraci√≥n
def verify_complete_setup():
    print("üîç VERIFICACI√ìN COMPLETA DEL ENTORNO")
    print("=" * 50)
    
    checks = []
    
    # Check 1: Databricks Secrets
    try:
        dbutils.secrets.get("azure-storage-secrets", "storage-account-name")
        checks.append("‚úÖ Databricks Secrets configurados")
    except:
        checks.append("‚ùå Databricks Secrets faltantes")
    
    # Check 2: Azure Storage Connection
    if storage_client:
        checks.append("‚úÖ Conexi√≥n a Azure Storage")
    else:
        checks.append("‚ùå Sin conexi√≥n a Azure Storage")
    
    # Check 3: Estructura del proyecto
    try:
        container_client = storage_client.get_container_client(container_name)
        blobs = list(container_client.list_blobs())
        if len(blobs) >= 3:
            checks.append("‚úÖ Estructura Medallion creada")
        else:
            checks.append("‚ùå Estructura Medallion incompleta")
    except:
        checks.append("‚ùå Error verificando estructura")
    
    # Mostrar resultados
    for check in checks:
        print(f"   {check}")
    
    all_good = all("‚úÖ" in check for check in checks)
    
    if all_good:
        print("\nüéâ ¬°Configuraci√≥n completa y exitosa!")
        print("üìç Listo para la Fase 2: Carga de datos")
    else:
        print("\n‚ö†Ô∏è  Hay elementos por configurar")
        print("üìç Revisa los elementos marcados con ‚ùå")

# Ejecutar verificaci√≥n
verify_complete_setup()
```

-----

## **Resumen de la Fase 1**

### **‚úÖ Elementos Configurados:**

1. **Databricks Community Edition**
- ‚úÖ Cuenta creada y verificada
- ‚úÖ Workspace activo
- ‚úÖ Interfaz explorada
1. **Cl√∫ster Computacional**
- ‚úÖ Cl√∫ster creado con configuraci√≥n √≥ptima
- ‚úÖ Runtime LTS seleccionado
- ‚úÖ Estado activo (c√≠rculo verde)
1. **Azure Storage Account**
- ‚úÖ Permisos verificados en Portal Azure
- ‚úÖ Credenciales obtenidas
- ‚úÖ Databricks Secrets configurados
- ‚úÖ Conexi√≥n establecida
1. **Estructura del Proyecto**
- ‚úÖ Contenedor `alopez-proyecto-gh` creado
- ‚úÖ Medallion Architecture implementada:
  - ü•â **Bronze:** Datos en bruto
  - ü•à **Silver:** Datos procesados
  - ü•á **Gold:** Datos para an√°lisis

### **üéØ Pr√≥ximo Paso:**

**[‚û°Ô∏è Fase 2: Carga y Almacenamiento (Capa Bronze)](./fase-2-capa-bronze.md)**

### **üìö Material de Apoyo:**

- **Databricks:** [Documentaci√≥n Oficial](https://docs.databricks.com/getting-started/index.html)
- **Azure Storage:** [Gu√≠a de Python SDK](https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-python)
- **Medallion Architecture:** [Conceptos y mejores pr√°cticas](https://databricks.com/glossary/medallion-architecture)

