# **Fase 1: Configuraci√≥n del Entorno en Databricks**

## **Introducci√≥n**

Antes de poder construir cualquier pipeline de datos, necesitamos preparar nuestro espacio de trabajo. Esto implica registrarnos en Databricks Community Edition, crear un cl√∫ster computacional, y configurar Azure Storage Account como nuestro sistema de almacenamiento externo. Esta configuraci√≥n nos permitir√° implementar la **Medallion Architecture** (Bronze-Silver-Gold) para nuestro proyecto de an√°lisis de datos de GitHub.

-----

## **Paso 1.1: Registrarse en Databricks Community Edition**

La Community Edition es una versi√≥n gratuita de Databricks, ideal para aprender y desarrollar proyectos personales.

### **Proceso de Registro:**

1. **Ve a la p√°gina de registro:**
- Abre tu navegador y dir√≠gete a: [Databricks Community Edition](https://community.cloud.databricks.com/login.html)
1. **Completa el formulario:**
- Rellena tus datos personales
- Aseg√∫rate de usar un correo electr√≥nico v√°lido
- Crea una contrase√±a segura
1. **Selecciona la opci√≥n ‚ÄúCommunity Edition‚Äù:**
- Cuando se te presente la opci√≥n de elegir un plan
- Selecciona **‚ÄúGet started with Community Edition‚Äù**
1. **Verifica tu correo electr√≥nico:**
- Recibir√°s un correo para confirmar tu cuenta
- Sigue las instrucciones para activar tu workspace

### **Material de Apoyo:**

- **Documentaci√≥n Oficial:** [Gu√≠a de inicio de Databricks](https://docs.databricks.com/getting-started/community-edition.html)

-----

## **Paso 1.2: Explorando la Interfaz de Databricks**

Una vez dentro de tu workspace, familiar√≠zate con la interfaz principal.

### **Componentes Principales:**

|Secci√≥n      |Descripci√≥n                            |Uso en el Proyecto                |
|-------------|---------------------------------------|----------------------------------|
|**Workspace**|Organiza carpetas, notebooks y archivos|Crear estructura del proyecto     |
|**Compute**  |Gestiona cl√∫steres computacionales     |Crear y administrar el cl√∫ster    |
|**Data**     |Explora bases de datos y tablas        |Visualizar datos transformados    |
|**Jobs**     |Automatiza ejecuci√≥n de notebooks      |Para etapas avanzadas del proyecto|

### **Navegaci√≥n B√°sica:**

- **Men√∫ lateral izquierdo:** Acceso r√°pido a todas las secciones
- **√Årea principal:** Espacio de trabajo principal
- **Barra superior:** Configuraciones de usuario y workspace

-----

## **Paso 1.3: Verificando tu Entorno Computacional**

Databricks Community Edition viene con un **Serverless Starter Warehouse** preconfigurado que actuar√° como nuestro motor computacional para procesar datos.

### **Verificaci√≥n del Serverless Warehouse:**

1. **Navega a la secci√≥n "Compute":**
   - Haz clic en el √≠cono **"Compute"** en el men√∫ lateral

2. **Verificar el Serverless Warehouse:**
   - Deber√≠as ver un warehouse llamado **"Starter Warehouse"** o similar
   - **Estado:** Debe aparecer como "Running" o con un c√≠rculo verde
   - **Tipo:** Serverless (Sin necesidad de configuraci√≥n manual)

3. **Si el warehouse no est√° activo:**
   - Haz clic en el warehouse para seleccionarlo
   - Clic en **"Start"** si est√° detenido
   - El proceso toma 1-2 minutos en iniciarse

4. **Verificaci√≥n completa:**
   - **Estado activo:** C√≠rculo verde junto al nombre
   - **Tipo:** Serverless Starter Warehouse
   - **Listo para usar:** Sin configuraci√≥n adicional necesaria

### **Limitaciones Community Edition:**
- ‚úÖ **Permitido:** Serverless Starter Warehouse (Ya creado)
- ‚ùå **Limitado:** Sin acceso a funcionalidades premium
- ‚ùå **Limitado:** Sin almacenamiento persistente integrado

### **Material de Apoyo:**
- **Documentaci√≥n Oficial:** [Databricks Serverless Compute](https://docs.databricks.com/compute/serverless.html)

-----

## **Paso 1.4: Configurando Azure Storage Account**

Dado que Databricks Community Edition no permite almacenamiento persistente integrado, configuraremos Azure Storage Account como nuestro sistema de almacenamiento externo.

### **0. Validaci√≥n del Acceso a Azure**

#### **Informaci√≥n del Proyecto:**
- **Grupo de Recursos:** `rg-proyecto-github`
- **Storage Account:** `stgaccproyectogh`

#### **Verificaci√≥n de Permisos (Paso a Paso):**

1. **Acceder al grupo de recursos:**
   - Ve a: [Azure Portal](https://portal.azure.com)
   - En la barra de b√∫squeda superior, escribe: `rg-proyecto-github`
   - Haz clic en el grupo de recursos **"rg-proyecto-github"** cuando aparezca en los resultados
   - Esto te llevar√° al dashboard del grupo de recursos

2. **Navegar a Access Control (IAM):**
   - Men√∫ lateral ‚Üí **"Access control (IAM)"**
   - Pesta√±as superiores visibles

3. **Verificar permisos espec√≠ficos:**
   - Secci√≥n **"My access"** ‚Üí Bot√≥n **"View my access"**
   - Panel derecho: **"assignments - rg-proyecto-github"**

4. **Confirmar roles asignados:**

| Role | Description | Scope | Status |
|------|-------------|-------|--------|
| **Reader** | View all resources, but does not allow modifications | Subscription (inherited) | ‚úÖ Requerido |
| **Storage Account Contributor** | Lets you manage storage accounts and access keys | This resource | ‚úÖ Requerido |
| **Storage Blob Data Contributor** | Allows for read, write and delete access to blobs | This resource | ‚úÖ Requerido |

#### **Obtenci√≥n de Credenciales:**

1. **Localizar Storage Account:**
   - En el grupo de recursos, buscar el recurso **"stgaccproyectogh"** (tipo: Storage account)
   - Hacer clic en el nombre del Storage Account: **stgaccproyectogh**

2. **Acceder a las claves:**
   - Men√∫ lateral ‚Üí **"Security + networking"** ‚Üí **"Access keys"**
   - Copiar **Storage account name:** `stgaccproyectogh`
   - Revelar y copiar **Key 1** o **Key 2**

### **1. Configurar Databricks Secrets**

#### **üí° Enfoque H√≠brido: UI + Python SDK**

**Ventajas de este m√©todo:**
- ‚úÖ **UI para Scope:** Visual y f√°cil de entender
- ‚úÖ **SDK para Secrets:** Program√°tico y reproducible  
- ‚úÖ **Sin limitaciones:** No depende de URLs espec√≠ficas
- ‚úÖ **M√°s control:** Manejo directo de errores
- ‚úÖ **Documentable:** C√≥digo que se puede versionar

Utilizaremos la **interfaz web** para crear el scope (m√°s visual) y **Python SDK** para agregar secrets (m√°s program√°tico y reproducible).

#### **Crear Secret Scope (Desde la UI):**

1. **Navegar a secrets en Databricks:**
   - En tu workspace de Databricks, agrega `#secrets/createScope` al final de la URL
   - URL: `https://tu-workspace.cloud.databricks.com/#secrets/createScope`

2. **Configurar el Scope:**
   - **Scope Name:** `azure-storage-secrets`
   - **Manage Principal:** Creator (por defecto)
   - Haz clic en **"Create"**

#### **Agregar Secrets (Usando Python SDK):**

Una vez creado el scope, ejecuta este c√≥digo en una celda de tu notebook:

```python
# Instalar Databricks SDK si no est√° disponible
%pip install databricks-sdk

# Importar y configurar el cliente
from databricks.sdk import WorkspaceClient

# Inicializar cliente de Databricks
w = WorkspaceClient()

# Agregar el nombre del Storage Account
w.secrets.put_secret(
    scope="azure-storage-secrets",
    key="storage-account-name", 
    string_value="stgaccproyectogh"
)

# Agregar la clave de acceso del Storage Account
# IMPORTANTE: Reemplaza "TU_STORAGE_ACCOUNT_KEY" con la clave real obtenida del Portal Azure
w.secrets.put_secret(
    scope="azure-storage-secrets",
    key="storage-account-key",
    string_value="TU_STORAGE_ACCOUNT_KEY"  # ‚Üê Reemplazar con la clave real
)

print("‚úÖ Secrets configurados exitosamente:")
print("   - storage-account-name: stgaccproyectogh")
print("   - storage-account-key: [OCULTA]")
```

#### **Verificar Secrets Configurados:**

```python
# Verificar que los secrets se crearon correctamente
try:
    # Listar scopes
    scopes = w.secrets.list_scopes()
    target_scope = "azure-storage-secrets"
    
    if any(scope.name == target_scope for scope in scopes):
        print(f"‚úÖ Scope '{target_scope}' encontrado")
        
        # Listar secrets en el scope
        secrets = w.secrets.list_secrets(scope=target_scope)
        secret_keys = [secret.key for secret in secrets]
        print(f"üîë Secrets disponibles: {secret_keys}")
        
        # Verificar que tenemos los secrets necesarios
        required_keys = ["storage-account-name", "storage-account-key"]
        if all(key in secret_keys for key in required_keys):
            print("üéâ Todos los secrets requeridos est√°n configurados")
        else:
            missing = [key for key in required_keys if key not in secret_keys]
            print(f"‚ùå Faltan estos secrets: {missing}")
    else:
        print(f"‚ùå Scope '{target_scope}' no encontrado")
        
except Exception as e:
    print(f"‚ùå Error verificando secrets: {e}")
```

### **2. Configurar Conexi√≥n en Databricks**

#### **C√≥digo de Configuraci√≥n (Notebook):**

```python
# Verificar configuraci√≥n de secrets usando dbutils (m√©todo tradicional)
print("üîç Verificando configuraci√≥n de secrets...")
try:
    scopes = dbutils.secrets.listScopes()
    target_scope = "azure-storage-secrets"
    
    if target_scope in [scope.name for scope in scopes]:
        secrets = dbutils.secrets.list(target_scope)
        secret_keys = [secret.key for secret in secrets]
        print(f"‚úÖ Scope encontrado: {target_scope}")
        print(f"üîë Secrets disponibles: {secret_keys}")
        
        # Verificar que tenemos los secrets necesarios
        required_keys = ["storage-account-name", "storage-account-key"]
        if all(key in secret_keys for key in required_keys):
            print("üéâ Todos los secrets requeridos est√°n configurados")
        else:
            missing = [key for key in required_keys if key not in secret_keys]
            print(f"‚ùå Faltan estos secrets: {missing}")
    else:
        print(f"‚ùå Scope '{target_scope}' no encontrado")
        
except Exception as e:
    print(f"‚ùå Error: {e}")
```

```python
# Configurar cliente de Azure Storage
%pip install azure-storage-blob

from azure.storage.blob import BlobServiceClient

def get_storage_client():
    try:
        # Obtener credenciales desde secrets
        storage_account_name = dbutils.secrets.get(scope="azure-storage-secrets", key="storage-account-name")
        storage_account_key = dbutils.secrets.get(scope="azure-storage-secrets", key="storage-account-key")
        
        # Crear connection string
        connection_string = f"DefaultEndpointsProtocol=https;AccountName={storage_account_name};AccountKey={storage_account_key};EndpointSuffix=core.windows.net"
        
        # Crear cliente
        blob_service_client = BlobServiceClient.from_connection_string(connection_string)
        
        # Test de conexi√≥n
        containers = list(blob_service_client.list_containers())
        print(f"‚úÖ Conectado a Azure Storage: {storage_account_name}")
        print(f"üì¶ Contenedores encontrados: {len(containers)}")
        
        return blob_service_client
        
    except Exception as e:
        print(f"‚ùå Error de conexi√≥n: {e}")
        return None

# Inicializar cliente
storage_client = get_storage_client()
```

### **3. Crear Estructura del Proyecto**

En este paso vas a crear un contenedor con la siguiente sintaxis:
> primeraLetraNombrePrimerApellido-proyecto-gh -->> Ejemplo alopez-proyecto-gh


Validar que no exista otro contenedor ya creado con este nombre, si es asi utiliza la siguiente sintaxis:
> primeraLetraNombrePrimerApellidoPrimeraLetraSegundoApellido-proyecto-gh -->> Ejemplo alopezm-proyecto-gh

#### **Configurar Medallion Architecture:**

```python
# Configuraci√≥n del proyecto
container_name = "nombre-contenedor"
folders = ["bronze", "silver", "gold"]

def setup_project_structure():
    if not storage_client:
        print("‚ùå Cliente no disponible")
        return False
    
    try:
        # Crear contenedor
        try:
            container_client = storage_client.create_container(container_name)
            print(f"‚úÖ Contenedor '{container_name}' creado")
        except Exception as e:
            if "ContainerAlreadyExists" in str(e):
                print(f"‚ÑπÔ∏è  Contenedor '{container_name}' ya existe")
        
        # Crear carpetas (Bronze, Silver, Gold)
        for folder in folders:
            blob_name = f"{folder}/.placeholder"
            blob_client = storage_client.get_blob_client(container=container_name, blob=blob_name)
            blob_client.upload_blob(f"# Carpeta {folder} - Medallion Architecture", overwrite=True)
            print(f"‚úÖ Carpeta '{folder}' creada")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error: {e}")
        return False

# Ejecutar configuraci√≥n
setup_project_structure()
```

### **4. Verificar Configuraci√≥n Completa**

#### **Checklist de Validaci√≥n:**

```python
# Verificaci√≥n final de la configuraci√≥n
def verify_complete_setup():
    print("üîç VERIFICACI√ìN COMPLETA DEL ENTORNO")
    print("=" * 50)
    
    checks = []
    
    # Check 1: Databricks Secrets
    try:
        dbutils.secrets.get("azure-storage-secrets", "storage-account-name")
        checks.append("‚úÖ Databricks Secrets configurados")
    except:
        checks.append("‚ùå Databricks Secrets faltantes")
    
    # Check 2: Azure Storage Connection
    if storage_client:
        checks.append("‚úÖ Conexi√≥n a Azure Storage")
    else:
        checks.append("‚ùå Sin conexi√≥n a Azure Storage")
    
    # Check 3: Estructura del proyecto
    try:
        container_client = storage_client.get_container_client(container_name)
        blobs = list(container_client.list_blobs())
        if len(blobs) >= 3:
            checks.append("‚úÖ Estructura Medallion creada")
        else:
            checks.append("‚ùå Estructura Medallion incompleta")
    except:
        checks.append("‚ùå Error verificando estructura")
    
    # Mostrar resultados
    for check in checks:
        print(f"   {check}")
    
    all_good = all("‚úÖ" in check for check in checks)
    
    if all_good:
        print("\nüéâ ¬°Configuraci√≥n completa y exitosa!")
        print("üìç Listo para la Fase 2: Carga de datos")
    else:
        print("\n‚ö†Ô∏è  Hay elementos por configurar")
        print("üìç Revisa los elementos marcados con ‚ùå")

# Ejecutar verificaci√≥n
verify_complete_setup()
```

-----

## **Resumen de la Fase 1**

### **‚úÖ Elementos Configurados:**

1. **Databricks Community Edition**
   - ‚úÖ Cuenta creada y verificada
   - ‚úÖ Workspace activo
   - ‚úÖ Interfaz explorada

2. **Serverless Warehouse**
   - ‚úÖ Starter Warehouse verificado y activo
   - ‚úÖ Estado "Running" confirmado
   - ‚úÖ Listo para procesar datos

3. **Azure Storage Account**
   - ‚úÖ Permisos verificados en Portal Azure
   - ‚úÖ Storage Account `stgaccproyectogh` configurado  
   - ‚úÖ Databricks Secrets configurados (UI + SDK)
   - ‚úÖ Conexi√≥n establecida y probada

4. **Estructura del Proyecto**
   - ‚úÖ Contenedor `nombre-contenedor` creado
   - ‚úÖ Medallion Architecture implementada:
     - ü•â **Bronze:** Datos en bruto
     - ü•à **Silver:** Datos procesados
     - ü•á **Gold:** Datos para an√°lisis

### **üéØ Pr√≥ximo Paso:**

**[‚û°Ô∏è Fase 2: Carga y Almacenamiento (Capa Bronze)](./fase-2-capa-bronze.md)**

### **üìö Material de Apoyo:**

- **Databricks:** [Documentaci√≥n Oficial](https://docs.databricks.com/getting-started/index.html)
- **Databricks SDK:** [Python SDK Documentation](https://databricks-sdk-py.readthedocs.io/)
- **Azure Storage:** [Gu√≠a de Python SDK](https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-python)
- **Medallion Architecture:** [Conceptos y mejores pr√°cticas](https://databricks.com/glossary/medallion-architecture)